# Introduction

## 문제 제기

클로드 모네가 그림을 그릴 때 컬러 사진기가 발명되었더라면 그의 그림은 어쩌면 그저 사진으로 기록되었을 수 있다. 당시 컬러 사진기는 없었기에, 모네는 봄에 대한 그의 인상을 거친 붓질과 밝은색의 컬러로 표현했다. 모네의 그림을 보다보면 그가 현실의 장면을 어떻게 상상했는지 알 수 있다. 튄 물감의 굴곡과 평평하고 밝은 부분, 파스텔색의 그림자 표현으로 모네는 그가 본 장면을 표현했다.

사람은 모네의 그림 몇 가지만 보고도 그림의 특징을 기억해 실사 사진을 모네의 그림처럼 상상해 볼 수 있다. **'A가 B처럼 생겼더라면 어땠을까?'**라고 상상하며 머릿속에서 이미지를 변환한다. 이 논문에선 이러한 과정을 학습하는 방법을 고안한다. 짝지어진 이미지 세트가 없어도, 두 도메인에 해당하는 이미지의 특징을 학습하고 이 특징이 다른 도메인의 특징으로 어떻게 변환될지 학습할 수 있도록 한다.

이 과정은 그림-사진 변환 뿐만 아니라 일반적인 이미지간 변환에서도 적용된다. 흑백-컬러 변환, 이미지-레이블 등, 컴퓨터비젼에서 오랫동안 연구되어온 주제에 대해서도 같은 이야기를 할 수 있다. 이 경우엔 이미지 쌍이 주어져 지도학습적 시스템으로 작동할 수 있었다. 그러나 많은 입출력 이미지 쌍을 구하기 매우 어렵다. 잘 정의 되어있지 않은 경우가 대부분이다.

따라서 이런 경우에도 문제를 해결할 알고리즘이 필요했다. 저자들은 다른 두 도메인 사이에, **같은 대상을 다르게 표현하는 잠재적 관계**가 있다고 가정하고 이를 학습할 수 있는 방법을 탐색했다.

{% hint style="info" %}
같은 사진(장면)을 다른 화가의 그림으로 표현하는 것 처럼, 같은 말의 형태지만 다른 무늬(말-얼룩말)로 나타나는 것처럼 같은 대상에 대해 두 표현방법이 나타난다.
{% endhint %}

## 접근 방법

​이미지-이미지 관계에서 supervising하는것이 아닌 두 도메인의 데이터셋 단에서 supervising한다. 단순히 $$G:X\rightarrow Y$$를 학습해 $$\hat y=G(x)$$를 생성하도록 할 수 있다. 이론적으로 가능하지만, 매핑 $$G$$는 무한히 많기 때문에 입력과 출력이 의미있게 매핑되도록 최적화됨을 보장할 수 없다.

{% hint style="success" %}
$$\hat y = G(x)$$를 $$y$$의 분포와 구별할 수 없도록 adversarial하게 학습시킨다고 하자. 도메인 변환의 본래 목적은, $$x$$의 기본적 특징은 유지한 채 표현법만 바꾸는 것이다. $$G:X\rightarrow Y$$는 판별함수가 $$\hat Y$$와 $$Y$$를 구분할 수 없도록만 생성하면 되고 판별기는 분포만을 비교하므로 조건이 더 필요하다.

간단히 말해, \*\*사진를 고흐 그림처럼 바꾸려고 \*\*$$G$$**에 넣었으나 넣은 사진과는 전혀 다른 사진의 고흐 버전이 나올 수 있다.**
{% endhint %}

또한 GAN에서 자주 일어나는 문제인 mode collapse를 다루는 데 일반적인 방법으로 부족하다는 것을 알았다.

{% hint style="info" %}
Mode Collapse란 Generator가 Discriminator를 속이기 쉬운 소수의 샘플로만 최적화되어 같은 이미지만을 생성하게 되는 문제를 말한다. Generator가 local minimum에 빠진 상태이다. (ref: [https://velog.io/@tobigs-gm1/basicofgan](https://velog.io/@tobigs-gm1/basicofgan))
{% endhint %}

따라서 새로운 목적함수를 고안할 필요가 있다. 두 도메인 간 변환은 순방향 변환 후 역방향 변환했을 때 원래의 형태를 일관되게 유지해야 한다는, 'cycle consistent'해야한다는 점을 이용해 목적함수를 고안한다. 즉, $$G$$와 $$F$$가 일종의 역함수 관계에 있어야 하며 이 둘 모두를 학습한다. 이 cycle consistency loss를 기존의 adversarial loss와 합쳐 도메인 변환이 최적화될 수 있도록 한다.

## Related Work

* Image-to-Image Translation
  * pix2pix, Conditional GAN, ...
* Unpaired Image-to-Image Translation
  * CoGAN, VAE+GAN
* Cycle Consistency
* Neural Style Transfer
